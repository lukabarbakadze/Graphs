{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import remove_isolated_nodes, to_networkx\n",
    "\n",
    "from Graph_Nets import GCNetwork, GANetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer()\n",
      "-------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 3327\n",
      "Number of features: 3703\n",
      "Number of classes: 6\n",
      "\n",
      "Graph:\n",
      "------\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: True\n",
      "Graph has loops: False\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root=\".\", name=\"CiteSeer\")\n",
    "data = dataset[0]\n",
    "\n",
    "print(f'Dataset: {dataset}')\n",
    "print('-------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Print information about the Dataset\n",
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of isolated nodes = 48\n"
     ]
    }
   ],
   "source": [
    "isolated = (remove_isolated_nodes(data['edge_index'])[2] == False).sum(dim=0).item()\n",
    "print(f'Number of isolated nodes = {isolated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = to_networkx(data)\n",
    "order = sorted(list(g.nodes()))\n",
    "A = nx.adjacency_matrix(g, nodelist=order)\n",
    "A = A.todense()\n",
    "I = np.eye(A.shape[0])\n",
    "A = A + I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, A = data.x, data.y, torch.Tensor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3327, 3703]), torch.Size([3327]), torch.Size([3327, 3327]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, A.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = data.x.size(1)\n",
    "out_features = 100\n",
    "n_classes = dataset.num_classes\n",
    "num_heads = 4\n",
    "bias = True\n",
    "alpha = 0.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN = GCNetwork(in_features=in_features, \n",
    "                out_features=out_features, \n",
    "                n_classes=n_classes, \n",
    "                bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "lr_rate=0.01\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(GCN.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | train loss: 1.7959004640579224 | train accuracy: 0.1666666716337204 | val loss: 1.8095452785491943 | val accuracy 0.06800000369548798\n",
      "Epoch: 1 | train loss: 1.5769823789596558 | train accuracy: 0.875 | val loss: 1.7483713626861572 | val accuracy 0.28999999165534973\n",
      "Epoch: 2 | train loss: 1.2074047327041626 | train accuracy: 1.0 | val loss: 1.6158791780471802 | val accuracy 0.6019999980926514\n",
      "Epoch: 3 | train loss: 0.7897706627845764 | train accuracy: 1.0 | val loss: 1.4578791856765747 | val accuracy 0.6340000033378601\n",
      "Epoch: 4 | train loss: 0.44315972924232483 | train accuracy: 1.0 | val loss: 1.3113090991973877 | val accuracy 0.6399999856948853\n",
      "Epoch: 5 | train loss: 0.21667322516441345 | train accuracy: 1.0 | val loss: 1.19483482837677 | val accuracy 0.6499999761581421\n",
      "Epoch: 6 | train loss: 0.09539853036403656 | train accuracy: 1.0 | val loss: 1.1201817989349365 | val accuracy 0.6480000019073486\n",
      "Epoch: 7 | train loss: 0.04006306454539299 | train accuracy: 1.0 | val loss: 1.0872100591659546 | val accuracy 0.6520000100135803\n",
      "Epoch: 8 | train loss: 0.017024746164679527 | train accuracy: 1.0 | val loss: 1.085422158241272 | val accuracy 0.6579999923706055\n",
      "Epoch: 9 | train loss: 0.007571505382657051 | train accuracy: 1.0 | val loss: 1.1038949489593506 | val accuracy 0.6480000019073486\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    GCN.train()\n",
    "    preds = GCN(X, A)\n",
    "    loss = loss_fn(preds[data.train_mask], data.y[data.train_mask])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    acc = float((torch.argmax(F.softmax(preds[data.train_mask], dim=1), axis=1) == data.y[data.train_mask]).sum() / data.y[data.train_mask].shape[0])\n",
    "\n",
    "    val_loss = loss_fn(preds[data.val_mask], data.y[data.val_mask])\n",
    "    val_acc = float((torch.argmax(F.softmax(preds[data.val_mask], dim=1), axis=1) == data.y[data.val_mask]).sum() / data.y[data.val_mask].shape[0])\n",
    "\n",
    "    print(f'Epoch: {epoch} | train loss: {loss.item()} | train accuracy: {acc} | val loss: {val_loss.item()} | val accuracy {val_acc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Attantion Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = GANetwork(in_features=in_features, \n",
    "                out_features=out_features, \n",
    "                n_classes=n_classes, \n",
    "                num_heads=num_heads, \n",
    "                alpha=alpha, \n",
    "                bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "lr_rate=0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(GAN.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, A = X.unsqueeze(axis=0), A.unsqueeze(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | train loss: 1.7881513833999634 | train accuracy: 0.15833333134651184 | val loss: 1.793402075767517 | val accuracy 0.1679999977350235\n",
      "Epoch: 1 | train loss: 1.6587295532226562 | train accuracy: 0.9583333134651184 | val loss: 1.75005042552948 | val accuracy 0.44600000977516174\n",
      "Epoch: 2 | train loss: 1.5306812524795532 | train accuracy: 0.9916666746139526 | val loss: 1.7071179151535034 | val accuracy 0.6060000061988831\n",
      "Epoch: 3 | train loss: 1.401977777481079 | train accuracy: 0.9916666746139526 | val loss: 1.6637402772903442 | val accuracy 0.6579999923706055\n",
      "Epoch: 4 | train loss: 1.2729523181915283 | train accuracy: 0.9916666746139526 | val loss: 1.619776725769043 | val accuracy 0.6579999923706055\n",
      "Epoch: 5 | train loss: 1.1448097229003906 | train accuracy: 0.9916666746139526 | val loss: 1.575353741645813 | val accuracy 0.6600000262260437\n",
      "Epoch: 6 | train loss: 1.0190941095352173 | train accuracy: 0.9916666746139526 | val loss: 1.5308476686477661 | val accuracy 0.6639999747276306\n",
      "Epoch: 7 | train loss: 0.8974925875663757 | train accuracy: 0.9916666746139526 | val loss: 1.486645221710205 | val accuracy 0.6600000262260437\n",
      "Epoch: 8 | train loss: 0.7817067503929138 | train accuracy: 0.9916666746139526 | val loss: 1.4431370496749878 | val accuracy 0.6600000262260437\n",
      "Epoch: 9 | train loss: 0.67329341173172 | train accuracy: 0.9916666746139526 | val loss: 1.4008142948150635 | val accuracy 0.6600000262260437\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    preds = GAN(X, A)\n",
    "    loss = loss_fn(preds.squeeze(axis=0)[data.train_mask], data.y[data.train_mask])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    acc = float((torch.argmax(F.softmax(preds.squeeze(axis=0)[data.train_mask], dim=1), axis=1) == data.y[data.train_mask]).sum() / data.y[data.train_mask].shape[0])\n",
    "\n",
    "    val_loss = loss_fn(preds.squeeze(axis=0)[data.val_mask], data.y[data.val_mask])\n",
    "    val_acc = float((torch.argmax(F.softmax(preds.squeeze(axis=0)[data.val_mask], dim=1), axis=1) == data.y[data.val_mask]).sum() / data.y[data.val_mask].shape[0])\n",
    "\n",
    "    print(f'Epoch: {epoch} | train loss: {loss.item()} | train accuracy: {acc} | val loss: {val_loss.item()} | val accuracy {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = untrained_gat(data.x, data.edge_index)\n",
    "\n",
    "# # Train TSNE\n",
    "# tsne = TSNE(n_components=2, learning_rate='auto', init='pca').fit_transform(h.detach())\n",
    "\n",
    "# # Plot TSNE\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.axis('off')\n",
    "# plt.scatter(tsne[:, 0], tsne[:, 1], s=50, c=data.y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3327, 3703]), torch.Size([1, 3327, 3327]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3327, 400])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANetwork(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_features, \n",
    "                 out_features,\n",
    "                 n_classes,\n",
    "                 num_heads=4,\n",
    "                 alpha=0.2,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.num_heads = num_heads\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.W1 = nn.Linear(in_features, out_features * num_heads, bias=bias)\n",
    "        self.a1 = nn.Parameter(torch.Tensor(num_heads, 2 * out_features))\n",
    "\n",
    "        self.W2 = nn.Linear(out_features, out_features * num_heads)\n",
    "        self.a2 = nn.Parameter(torch.Tensor(num_heads, 2 * out_features))\n",
    "\n",
    "        self.W3 = nn.Linear(out_features * num_heads, out_features)\n",
    "        self.FL = nn.Linear(out_features * num_heads, n_classes)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.a1.data, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a2.data, gain=1.414)\n",
    "    \n",
    "    def attention_block(self, h, A, W, a):\n",
    "        # save batch size & number of features\n",
    "        batch_size, num_nodes = h.size(0), h.size(1)\n",
    "\n",
    "        # project X to Matrix W\n",
    "        Wh = W(h)\n",
    "\n",
    "        # separate each head via separate dimension\n",
    "        Wh = Wh.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "\n",
    "        # get edge matrix from A\n",
    "        edges = A.nonzero(as_tuple=False)\n",
    "\n",
    "        # remove batch dimension\n",
    "        Wh_flat_flat = Wh.view(batch_size * num_nodes, self.num_heads, -1)\n",
    "\n",
    "        # select indices of connected nodes\n",
    "        edge_indices_row = edges[:, 0] * num_nodes + edges[:, 1]\n",
    "        edge_indices_col = edges[:, 0] * num_nodes + edges[:, 2]\n",
    "\n",
    "        # select corresponding projected vectors from Wh_flat_flat Matrix (for connected pairs)\n",
    "        a_input = torch.cat(\n",
    "            [\n",
    "                torch.index_select(input=Wh_flat_flat, index=edge_indices_row, dim=0),\n",
    "                torch.index_select(input=Wh_flat_flat, index=edge_indices_col, dim=0),\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        # calculate attention logits & aplly Leaky_relu activation function\n",
    "        attn_logits = torch.einsum(\"bhc,hc->bh\", a_input, a)\n",
    "        attn_logits = F.leaky_relu(attn_logits)\n",
    "\n",
    "        # replace 0's by '-inf' as features with 0 value should not have attention power (softmax will nullify it)\n",
    "        attn_matrix = attn_logits.new_zeros(A.shape + (self.num_heads,)).fill_(float('-inf'))\n",
    "        attn_matrix[A.view(1, A.size(1), A.size(2), 1).repeat(1, 1, 1, self.num_heads) == 1] = attn_logits.reshape(-1)\n",
    "\n",
    "        # apply softmax to calculate attention scores\n",
    "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
    "\n",
    "        # use torch.einsum to get updated embeddings with size (batch_size, num_nodes, out_features * num_heads)\n",
    "        Wh = torch.einsum(\"bijh,bjhc->bihc\", attn_probs, Wh)\n",
    "        Wh = Wh.reshape(batch_size, num_nodes, -1)\n",
    "        return Wh\n",
    "\n",
    "    def forward(self, h, A):\n",
    "        h = self.attention_block(h, A, self.W1, self.a1) \n",
    "        h = self.W3(h)\n",
    "        h = self.attention_block(h, A, self.W2, self.a2)\n",
    "        out = self.FL(h)\n",
    "        return h, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = GANetwork(in_features=in_features, \n",
    "                out_features=out_features, \n",
    "                n_classes=n_classes, \n",
    "                num_heads=num_heads, \n",
    "                alpha=alpha, \n",
    "                bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb, logits = GAN(X, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3327, 400]), torch.Size([1, 3327, 6]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, logits.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
